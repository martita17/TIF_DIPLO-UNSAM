---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(tidytext)

```
```{r}
library(tidymodels)
library(tidyverse)
library(textrecipes)
```

La base modelo finalmente lo que tiene que tener es los documentos (id y texto), con su respectiva orientacion. 
```{r}
base_original<-read.csv("C:/Users/JGM/Documents/trabajo_final_diplomatura/TIF_DIPLO-UNSAM/bases/corpus_clean.csv") %>% 
  select(id,orientacion,texto,medio)
topicos_X_doc<-read.csv("C:/Users/JGM/Documents/trabajo_final_diplomatura/TIF_DIPLO-UNSAM/bases/doc_2_topic.csv") %>% 
  select(id,topic)
```

Unimos las bases y filtramos por tópico, nos quedamos con elecciones (4) y judiciales (12)

```{r}
base_modelo <- topicos_X_doc %>%   
  left_join(base_original, by = "id" ) %>% 
    filter(topic %in% c(4,12)) 
```

```{r}
unique(base_modelo$topic)
```


Se revisa el balance de clases
```{r}
peso_clases<-base_modelo %>% 
  group_by(topic,orientacion) %>% 
  summarise(count=n(), .groups = "drop") %>% 
  glimpse()
```

Para que la base funcione con los embeddings en español, es necesaria una limpieza más superficial: no se le quitan mayúsculas ni caractéres no ascii
```{r}
bmodelo_limpia <- base_modelo %>%
        mutate(texto = str_replace_all(texto, "'//[.*?¿//]//%'", " ")) %>%
        mutate(texto = str_replace_all(texto, "[[:digit:]]+", "DIGITO")) %>% 
        mutate(medio = as.numeric(as.factor(medio)))
        
```

Cargo los embeddings sugeridos
```{r embeddings}
load_embeddings <- function(path=NULL, type=c("w2v", "ft")){
        if (type=="w2v"){
                embedding <- word2vec::read.wordvectors(path, 
                                                        type = "bin", 
                                                        normalize = TRUE) %>%
                        as_tibble(rownames="word")
        }
        else if (type=="ft"){
                model <- fastTextR::ft_load(path)
                words <- fastTextR::ft_words(model)
                embedding <- fastTextR::ft_word_vectors(model,
                                                        words) %>%
                        as_tibble(rownames="word")
        }
        
        return(embedding)
}

embedding <- load_embeddings(
  path = "C:/Users/JGM/Documents/trabajo_final_diplomatura/TIF_DIPLO-UNSAM/bases/sbw_vectors.bin",
  type = "w2v"
)


```

De los dos tópicos preseleccionados, elijo uno. El valor elegido acá será el que se use para el código posterior, de esta manera se pueden hacer pruebas por tópico de manera más dinámica

```{r}
topico<-4
```

```{r}
bmodelo_filt<-bmodelo_limpia %>% 
  filter(topic == !!topico) %>% 
  select(-topic)
```

tidy models me permite usar recipies también para construir la matriz de embeddings que será insumo para el modelo. Por lo que le indicamos...se tokenizará todo menos la columna id (que le estamos dando el rol de ID) y la columna orientacion.
```{r recipe}
notas_rec_embed <- recipe(orientacion ~ ., data = bmodelo_filt) %>%
        update_role("id", new_role = "ID") %>% 
        step_tokenize(texto) %>% 
        step_word_embeddings(texto, 
                             embeddings=embedding,
                             aggregation = "mean")
```

Se aplica la receta
```{r prep}
tictoc::tic()
not_embed <- notas_rec_embed %>% prep() %>% bake(bmodelo_filt)
tictoc::toc()
```

Divido el dataset en validation, train y test para el modelo de progresion logaritmica
```{r}
set.seed(664)
notas_split <- initial_split(not_embed, strata = orientacion)
train_embed <- training(notas_split)
test_embed <- testing(notas_split)

```

 A continuación eligo el modelo, en esta caso progresión logarítmica tipo lasso. 
```{r modelo}
lasso_spec <- multinom_reg(
        penalty = tune(),
        mixture = 1) %>%
        set_mode("classification") %>%
        set_engine("glmnet",maxit = 200000)
```
 
 A continuación seteos varios: construyo un recipe y un workflow y una grilla de hiperparámetros, esta le indicará distintas combinaciones de parámetros, así nos quedamos con la que mejor funciona. También seteo la validación cruzada
```{r}
library(themis)
notas_rec_embed <-
        recipe(orientacion ~ ., data = train_embed) %>%
        update_role("id", new_role = "ID") %>% 
       step_upsample(orientacion)
       


wf_embed <- workflow() %>% 
        add_recipe(notas_rec_embed) %>%
        add_model(lasso_spec)


grid_lasso <- grid_regular(penalty(), levels = 10)


set.seed(234)
embed_folds <- vfold_cv(train_embed, v = 5)

```
 
 Entrenamiento
```{r}
tictoc::tic()
tune_lasso_embed <- tune_grid(
        wf_embed,
        embed_folds,
        grid = grid_lasso,
        control = control_resamples(save_pred = TRUE)
)
tictoc::toc()
```
 
```{r}
show_best(tune_lasso_embed)
```

```{r}
chosen_auc_embed <- tune_lasso_embed %>%
  select_by_one_std_err(metric = "roc_auc", -penalty)

chosen_auc_embed
```

```{r}
final_params_lasso_embed <- finalize_workflow(wf_embed, chosen_auc_embed)
final_params_lasso_embed

```
Corremos el mejor modelo
```{r}
fitted_lasso_embed <- fit(final_params_lasso_embed, train_embed)
```

Hacemos el testeo con mejor modelo que teníamos
```{r}
preds_embed <- test_embed %>%
        select(orientacion) %>%
        bind_cols(predict(fitted_lasso_embed, test_embed, type="prob")) %>%
        bind_cols(predict(fitted_lasso_embed, test_embed, type="class"))
```

```{r}
glimpse(preds_embed)
```


Sacamos métricas del modelo en una tabla. Es una gt que se exporta a png para poder usarla en el informe      
```{r}
library(webshot2)
library(gt)
metricas_mod<-roc_auc(preds_embed, orientacion, `.pred_+ conservador`, `.pred_+ progresista`, `.pred_neutro`) %>%
bind_rows(accuracy(preds_embed, orientacion, .pred_class)) %>%
bind_rows(precision(preds_embed, orientacion, .pred_class)) %>%
bind_rows(recall(preds_embed, orientacion, .pred_class)) %>%
bind_rows(f_meas(preds_embed, orientacion, .pred_class)) %>% 
select(-.estimator)
  
  tabla<-metricas_mod %>% 
  gt() %>%
  tab_header(
    title = md("Métricas de performance"),  
    subtitle = paste("Regresión logística con tópico", topico, "**"))%>%
  cols_label(
    .metric = md("**Metrica**"),   # Rename .metric to "Metric" (bold)
    .estimate = md("**Estimado**") # Rename .estimate to "Estimate" (bold)
  ) %>%
  fmt_number(columns = vars(.estimate), decimals = 3) 

gtsave(tabla, "tabla_topico4_conmedio.png")
```
Tabla con las métricas del modelo
```{r}
roc_curve_data <- roc_curve(preds_embed, orientacion, `.pred_+ conservador`, `.pred_+ progresista`, `.pred_neutro`)
ggplot(roc_curve_data, aes(x = 1 - specificity, y = sensitivity, color = .level)) +
  geom_line(size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +  # Add diagonal reference line
  theme_minimal() +
  labs(
    title = paste("Curva ROC - Regresión logística con tópico", topico),
    x = "1 - Specificity",
    y = "Sensitivity",
    color = "Class"
  )+
  theme(
    legend.position = "bottom"
  )

```


Consigna 4: Diseñar un prompt para que Gemini (el LLM que usamos en clase) para realizar la tarea del punto anterior. Extraer una muestra de unos 800 articulos usados en el punto anterior y clasificarlos mediante Gemini. Comparar los resultados de ambos modelos. ¿Cuál funciona mejor? Generar las métricas y visualizaciones para comparar ambos modelos. ¿Cuáles podrían ser las causas de ambos comportamientos?

```{r}
library(gemini.R)
```

```{r}
api<-""
setAPI(api)
```

```{r}
prompt <- "A continuación vas a recibir un texto de una nota periodística.
  Quisiera que la clasifiques como conservadora, progresista o neutra usando las siguientes categorías:

-conservador: la nota indica una postura conservadora
-progresista: la nota indica una postura progresista
-neutro: la nota no da señales de ninguna postura. 

No justifiques tu respuesta, ni des información adicional, sólo contesta con una de estas tres categorias: conservador, progresista y neutro

Este es el texto:"

```

```{r}
base_gem<-bmodelo_filt
base_gem<-base_gem %>% 
  mutate(pred=NA)

```

```{r}

for (i in 1:nrow(base_gem)){
                cat("Procesando noticia", i, "de", nrow(base_gem), "\n")
                rta <- gemini(paste0(prompt, base_gem$texto[i]))
                base_gem$pred[i]=rta
                Sys.sleep(4.5)
                }


```
Normalizo y factorizo valores de orientacion y prediccion para poder compararlos 
```{r}
base_gem_reg <- base_gem %>%
  mutate(orientacion = case_when(
    orientacion == "+ conservador" ~ "Conservador",
    orientacion == "+ progresista" ~ "Progresista",
    orientacion == "neutro" ~ "Neutro",
    TRUE ~ orientacion
  )) %>% 
   mutate(pred = trimws(pred)) %>%
   mutate(pred = case_when(pred == "progresista" ~ "Progresista", TRUE ~ pred))%>%
  mutate(orientacion=as.factor(orientacion)) %>%
  mutate(pred=as.factor(pred)) %>% 
  glimpse()
  
  
  
```

```{r}
unique(base_gem_reg$pred)
```



Métricas de performance de gemini
```{r}
metrics1_gem<-accuracy(base_gem_reg,orientacion,pred) %>%
bind_rows(precision(base_gem_reg,orientacion,pred)) %>%
bind_rows(recall(base_gem_reg,orientacion,pred)) %>%
bind_rows(f_meas(base_gem_reg,orientacion,pred))
```
```{r}
metrics2_gem<-conf_mat(base_gem_reg,orientacion,pred)
```


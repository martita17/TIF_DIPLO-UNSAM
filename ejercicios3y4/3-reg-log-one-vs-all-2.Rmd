---
title: "Prueba Final"
output: html_document
date: "`r Sys.Date()`"
---

```{r}
preds_embed <- preds_embed %>% 
  rename(no_conserv = ".pred_no",
         si_conserv = ".pred_si",
         pred_conserv = ".pred_class")

preds_embed_neutro <- preds_embed_neutro %>% 
  rename(no_neutro = ".pred_no",
         si_neutro = ".pred_si",
         pred_neutro = ".pred_class")

preds_embed_progresista <- preds_embed_progresista %>% 
  rename(no_progre = ".pred_no",
         si_progre = ".pred_si",
         pred_progre = ".pred_class")

defainalcauntdaun <- preds_embed %>% 
  left_join(preds_embed_neutro, by = "id") %>% 
  left_join(preds_embed_progresista, by = "id") %>% 
  left_join(select(base_global, id, orientacion), by = "id")


defainalcauntdaun <- defainalcauntdaun %>% 
  mutate(prediccion = factor(case_when((si_conserv > si_neutro) & (si_conserv > si_progre) ~ "+ conservador",
                                (si_neutro > si_conserv) & (si_neutro > si_progre) ~ "neutro",
                                (si_progre > si_conserv) & (si_progre > si_neutro) ~ "+ progresista",
                                .default = "empate"), levels = c("+ conservador", "neutro", "+ progresista")),
         orientacion = as_factor(orientacion))
```


Con un poco de ayuda del Chat GPT modificamos el scipt para el cálculo de las métricas, debido a que el roc_auc debe ser calculado con un valor porcentual y nos enfrentamos a un problema multiclase.
```{r}
library(yardstick)
#No funca
metricas_finales <- roc_auc(defainalcauntdaun, si_conserv, si_neutro, si_progre, truth = orientacion) %>%
  bind_rows(accuracy(defainalcauntdaun, orientacion, prediccion)) %>%
  bind_rows(precision(defainalcauntdaun, orientacion, prediccion)) %>%
  bind_rows(recall(defainalcauntdaun, orientacion, prediccion)) %>%
  bind_rows(f_meas(defainalcauntdaun, orientacion, prediccion))

metricas_finales <- accuracy(defainalcauntdaun, orientacion, prediccion) %>%
  bind_rows(precision(defainalcauntdaun, orientacion, prediccion)) %>%
  bind_rows(recall(defainalcauntdaun, orientacion, prediccion)) %>%
  bind_rows(f_meas(defainalcauntdaun, orientacion, prediccion))

tabla_comparativa <- metricas_finales %>% 
  select(-.estimator) %>% 
  gt() %>% 
  tab_header(
    title = md("Métricas de performance - comparativa"),  
    subtitle = md("Regresión logística con tópico 4"))%>%
  cols_label(
    .metric = md("**Metrica**"),   # Rename .metric to "Metric" (bold)
    .estimate = md("**Estimado**") # Rename .estimate to "Estimate" (bold)
  ) %>%
  fmt_number(columns = c(.estimate), decimals = 3) 

gtsave(tabla_comparativa, "../visualizaciones/regresion-log/tabla_topico4_comparativa.png")



defainalcauntdaun <- defainalcauntdaun %>% 
  mutate(le_pego = case_when(orientacion == prediccion ~ 1,
                             orientacion != prediccion ~ 0))

defainalcauntdaun %>% 
  group_by(le_pego) %>% 
  summarise(le_pego = n())

defainalcauntdaun %>% 
  filter(le_pego == 1) %>% 
  summarise(le_pego = n())

bad_results <- defainalcauntdaun %>% 
  filter(le_pego == 0)

bad_results %>% 
  group_by(orientacion) %>% 
  summarise(orientacion = n()) %>% 
  ungroup()

bad_results %>% 
  group_by(prediccion) %>% 
  summarise(prediccion = n())
```





---
title: "TRABAJO FINAL INTEGRADOR"
subtitle: "Exploración y limpieza de datos"
author: "Fauquié - Peiretti - Tapia Serrano"
date: "`r Sys.Date()`"
output: 
  html_document: 
    theme: united
    fig_width: 10
    fig_height: 6
---

<br>

**Consigna**
Seleccionar las noticias vinculadas a algún tópico relevante (por ejemplo, “Elecciones”) y construir un clasificador para predecir la orientación del diario. Utilizar alguno de los modelos de clasificación vistos a lo largo de al Diplomatura (regresión logística, random forest, etc.). Utilizar como features el “Spanish Billion Word Corpus and Embeddings”, analizado en clase (pueden descargar el embedding en formato .bin del link). ¿Qué resultados arroja el modelo? ¿Es posible mediante el texto de las noticias conocer la línea editorial del diario? Generar las visualizaciones y tablas correspondientes para una correcta evaluación del modelo.

<br>
Para la realización de este ejercicio arrancamos seleccionando los dos tópicos más nutridos de notas: 4- Elecciones nacionales y 12- Inseguridad y judiciales. Dado que nos encontramos con un problema multicategorial, la primera prueba la hicimos con un modelo de **regresión logística multinomial**.

Dado que los resultados de la prueba no fueron buenos para ninguno de los dos modelos, decidimos probar otras estrategias tomando el tópico 4 como referencia (dado que es el que más observaciones tiene y sobre el que los resultados dieron apenas un poco mejor). Las pruebas que hicimos fueron:

[x] Regresión logística binomial (one vs all): calculamos 3 regresiones logísticas por separado, una para cada categoría. A partir de los resultados, determinamos la predicción poniendo a competir los porcentajes obtenidos para cada prueba.
[x] Regresión logística binomial (one vs one): elminamos de la base las observaciones neutras y probamos un modelo de regresión logística que buscaba predecir entre notas _conservadoras_ o _progresistas_.
[x] Random Forest: por último, con la intención de volver a probar un modelo que abordar el problema multicategorial en su conjunto, realizamos esta prueba.

Arrancamos...

#### Cargamos librerías y bases
```{r echo=TRUE, warning=FALSE, message=FALSE}
library(tidyverse)
library(tidytext)
library(tidymodels)
library(tidyverse)
library(textrecipes)
library(webshot2)
library(gt)

base_topicos <- read.csv(file = "../bases/base_ejercicio3.csv")
base_notas <- read.csv(file = "../bases/corpus_clean.csv")
```

<br>
Detectamos que ambas bases tienen una longitud diferente. La base que contiene el principal tópico de cada nota tiene una observación más. Esto se debe a que la entrada con id _40158_ está duplicada debido a que a tomado el mismo porcentaje para dos tópicos diferentes.
Realizo una revisión manual para remover el tópico que cobra menos sentido al momento de revisar el contenido del artículo. Habría que corregir la forma de generar la base de tópicos para forzar a que cuando hay empate, solamente traiga uno.
Tras la limpieza, joineamos ambas bases y generamos sets según tópico para realizar pruebas.

```{r}
base_topicos <- base_topicos[-5292,]

base_global <- base_notas %>% 
  left_join(base_topicos, by = "id")

base_global <- base_global %>% 
  mutate(nom_topico = case_when(topic == 1 ~ "costumbres e interes gral.",
                                topic == 2 ~ "derechos, educacion y salud",
                                topic == 3 ~ "politica internacional",
                                topic == 4 ~ "elecciones nacionales",
                                topic == 5 ~ "tecnologia y redes soc.",
                                topic == 6 ~ "chimento y farandula",
                                topic == 7 ~ "arte y espectaculos",
                                topic == 8 ~ "futbol y deportes",
                                topic == 9 ~ "siniestros viales",
                                topic == 10 ~ "agricultura y ganaderia",
                                topic == 11 ~ "economia",
                                topic == 12 ~ "inseguridad y judiciales")
         )

base_global %>% 
  count(nom_topico) %>% 
  mutate(porc_topic = round(n * 100 / sum(n), digits = 2)) %>% 
  arrange(-porc_topic)
```

<br>
Cargamos los embeddings propuestos para llevar adelante los procesamientos de este ejercicio.
```{r message=FALSE}
load_embeddings <- function(path=NULL, type=c("w2v", "ft")){
        if (type=="w2v"){
                embedding <- word2vec::read.wordvectors(path, 
                                                        type = "bin", 
                                                        normalize = TRUE) %>%
                        as_tibble(rownames="word")
        }
        else if (type=="ft"){
                model <- fastTextR::ft_load(path)
                words <- fastTextR::ft_words(model)
                embedding <- fastTextR::ft_word_vectors(model,
                                                        words) %>%
                        as_tibble(rownames="word")
        }
        
        return(embedding)
}

embedding <- load_embeddings(
  path = "../bases/sbw_vectors.bin",
  type = "w2v"
)
```


<br>
#### Regresión logística multinomial
**TÓPICO 4**
```{r}
topico4_elecciones <- base_global %>% 
  filter(nom_topico == "elecciones nacionales") %>% 
  select(id, orientacion, texto)

topico4_elecciones %>% 
  count(orientacion)
```

<br>
Para trabajar con los embeddings, la limpieza y normalización que debe atravesar el texto es distinta a la que ejecutamos para las pruebas anteriores (tf-idf y LDA). Por este motivo, hemos vuelto a traer la base con el texto original de las notas y, sobre ella, realizaremos un nuevo procedimiento de normalización/limpieza compatible con la estrategia propuesta por los embeddings.
```{r}
topico4_elecciones <- topico4_elecciones %>%
        mutate(texto = str_replace_all(texto, "'\\[.*?¿\\]\\%'", " ")) %>%
        mutate(texto = str_replace_all(texto, "[[:digit:]]+", "DIGITO"))
```

<br>
Aprovechamos el flujo de trabajo propuesto por tidymodels para obtener nuestra matriz de embedding para el tópico 4. El siguiente código nos permitirá tokenizar y luego vectorizar cada palabra de cada nota utilizando embeddings. Por último, a partir de los vectores generados, se calcula la media para cada una de las dimensiones, agrupando los términos en notas. Esto da como resultante un vector con la totalidad de las dimensiones propuestas que representa a cada una de las notas de la base de datos.
```{r}
topic4_embed <- recipe(orientacion ~ ., data = topico4_elecciones) %>% # definimos los diversos roles de las variables
        update_role("id", new_role = "ID") %>%  # asignamos a la columna id un rol id para que no sea considerada como variable predictora
        step_tokenize(texto) %>% 
        step_word_embeddings(texto, 
                             embeddings=embedding,
                             aggregation = "mean")

tictoc::tic()
notas_t4_embed <- topic4_embed %>% prep() %>% bake(topico4_elecciones)
tictoc::toc()
```

<br>
La base obtenido con los vectores calculados para cada una de las notas del tópico 4 no servirá también para entrenar el resto de los modelos. Lo mismo pasará con lo sets de entrenamiento y testeo que generaremos a continuación a partir del tópico en cuestión.
```{r}
set.seed(664)
notas_split_t4 <- initial_split(notas_t4_embed, strata = orientacion)
train_embed_t4 <- training(notas_split_t4)
test_embed_t4 <- testing(notas_split_t4)
```

<br>
A partir de las bases generadas estamos en condiciones de programar un nuevo flujo para procesar nuestro modelo de regresión logística multinomial.
```{r}
reg_multinom_t4 <- multinom_reg(
        penalty = tune(), # este es el hiperparámetro que definiremos a partir de las siguientes pruebas
        mixture = 1) %>%
        set_mode("classification") %>%
        set_engine("glmnet", maxit = 200000)

topic4_embed_rm <-
        recipe(orientacion ~ ., data = train_embed_t4) %>%
        update_role("id", new_role = "ID")

wf_embed_rm_t4 <- workflow() %>% 
        add_recipe(topic4_embed_rm) %>%
        add_model(reg_multinom_t4)

grid_lasso <- grid_regular(penalty(), levels = 10)

set.seed(234)
embed_folds_rm_t4 <- vfold_cv(train_embed_t4, v = 5)

tictoc::tic()
tune_penalty_rm_t4 <- tune_grid(
        wf_embed_rm_t4,
        embed_folds_rm_t4,
        grid = grid_lasso,
        control = control_resamples(save_pred = TRUE)
)
tictoc::toc()
```

<br>
Revisamos los mejores valores obtenidos para el penalty.
```{r}
show_best(tune_penalty_rm_t4)
```

<br>
Seleccionamos el mejor valor de todos.
```{r}
chosen_auc_embed_rm_t4 <- tune_penalty_rm_t4 %>%
  select_by_one_std_err(metric = "roc_auc", -penalty)

chosen_auc_embed_rm_t4
```

<br>
Una vez seleccionado el mejor penalty, estamos en condiciones de correr nuestro modelo sobre nuestra base de entrenamiento. Fijamos el workflow.
```{r}
final_wf_embed_rm_t4 <- finalize_workflow(wf_embed_rm_t4, chosen_auc_embed_rm_t4)
final_wf_embed_rm_t4
```

<br>
Y corremos el mejor modelo
```{r}
fitted_embed_rm_t4 <- fit(final_wf_embed_rm_t4, train_embed_t4)
```

<br>
Por último, lo resteamos.
```{r}
preds_embed_rm_t4 <- test_embed_t4 %>%
        select(id, orientacion) %>%
        bind_cols(predict(fitted_embed_rm_t4, test_embed_t4, type="prob")) %>%
        bind_cols(predict(fitted_embed_rm_t4, test_embed_t4, type="class"))
```

```{r}
glimpse(preds_embed_rm_t4)
```


Sacamos métricas del modelo...NO ME FUNCIONA ESTO       
```{r message=FALSE}
metricas_mod_rm_t4 <-
  roc_auc(preds_embed_rm_t4, orientacion, `.pred_+ conservador`, `.pred_+ progresista`, `.pred_neutro`) %>%
  bind_rows(accuracy(preds_embed_rm_t4, orientacion, .pred_class)) %>%
  bind_rows(precision(preds_embed_rm_t4, orientacion, .pred_class)) %>%
  bind_rows(recall(preds_embed_rm_t4, orientacion, .pred_class)) %>%
  bind_rows(f_meas(preds_embed_rm_t4, orientacion, .pred_class)) %>% 
  select(-.estimator)
  
tabla <- metricas_mod_rm_t4 %>% 
  gt() %>%
  tab_header(
    title = md("Métricas de performance"),  
    subtitle = "Regresión logística multinomial - Tópico 4") %>%
  cols_label(
    .metric = md("**Metrica**"),   # Rename .metric to "Metric" (bold)
    .estimate = md("**Estimado**") # Rename .estimate to "Estimate" (bold)
  ) %>%
  fmt_number(columns = vars(.estimate), decimals = 3) 

# gtsave(tabla, "../visualizaciones/metricas-modelos/Nuevas/tabla_topico4_reg_multinom.png")
```
<br>
Hacemos un gráfico de las curvas ROC
```{r}
roc_curve_rm_t4 <- roc_curve(preds_embed_rm_t4, orientacion, `.pred_+ conservador`, `.pred_+ progresista`, `.pred_neutro`)

ggplot(roc_curve_rm_t4, aes(x = 1 - specificity, y = sensitivity, color = .level)) +
  geom_line(size = 1.2) +
  geom_abline(linetype = "dashed", color = "gray") +  # Add diagonal reference line
  theme_minimal() +
  labs(
    title = "Curva ROC",
    subtitle = "Regresión logística multinomial - Tópico 4",
    x = "1 - Specificity",
    y = "Sensitivity",
    color = "Class"
  )+
  theme(
    legend.position = "bottom"
  )

```